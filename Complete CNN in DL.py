# -*- coding: utf-8 -*-
"""Copy of Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uAIOLYXhE6mJj2Dg8MCP93muK9uLWN5E
"""

import tensorflow as tf

from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

# Load and split Datasets
(train_images , train_labels),(test_images, test_labels)=datasets.cifar10.load_data()

#Normalize Pixel Values to be between 0 and 1
train_images , test_images = train_images/255.0 , test_images/255.0

class_names= ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']

# Lets look at a one image we change this to look at other images(img_index=1,2,3....)

IMG_INDEX=1
plt.imshow(train_images[IMG_INDEX],cmap=plt.cm.binary)
plt.xlabel(class_names[train_labels[IMG_INDEX][0]])
plt.show()

model=models.Sequential()
model.add(layers.Conv2D(32,(3,3), activation='relu',input_shape=(32,32,3)))
model.add(layers.MaxPooling2D((2,2))) #This layer will peform the max pooling operation using 2*2 sample and strides of 2
model.add(layers.Conv2D(64,(3,3), activation='relu'))
model.add(layers.MaxPooling2D((2,2)))
model.add(layers.Conv2D(64,(3,3),activation='relu'))

model.summary() #Lets have a look at our model so far

model.add(layers.Flatten())  #we need to take these extracted features and add a way to classify them
model.add(layers.Dense(64,activation='relu'))
model.add(layers.Dense(10))

model.summary()

# We can see tha flatten layer changes the shape of our data so that we can feed to the 64 nodes of dense layer
# followed by the final output layers, followed by the final output layer of 10 neurons (one for each class)

# Now we will train and complie the model using the recommand hyperparameters from tensorflow
model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history=model.fit(train_images,train_labels,epochs=10,validation_data=(test_images,test_labels))

# Train on 50000 samples and validate on 10000 samples
# Evaluate the model==> We can determine how well the model performed by looking at its performance on the test data

test_loss, test_acc = model.evaluate(test_images, test_labels,verbose=2)
print(test_acc)

# In this model we get our accuracy ~ 70% . this is okay but surely there is a way to improve on this by pretained model and fine tuning

# Pre-trained models and fine tunning==>



# A pre-trained model is a ml model that has been trained on a large dataset to perform a specific task such as image classification , natural language processing or speech recoginition
# These models are trained on powerful computing infrastructure and extensive labeled data, often using deep learning techniques
# The pre-training phase involoves exposing the model to a large amount of data and allowing it to learn patterns, features and representation that are useful for the given task

# During pre-training the model learns to extract relevant features from the input data and build internal representations that capture the underlying patterns for examples , in the case of an image classification model, the pre-trained model learns to recognizes shapes , edges and textures in images
# In the case of Natural language processing model, it learns to understand semantic relationships between words ands sentences

# Fine tuning on the other hand is a process where a pre-trained model is further trained on a smaller task 0 specific dataset to adapt it to a particular problem or domain . Fine tuning helps to transfer the knowledge gained during pre-training to a new more specific task. Instead of training a model from scratch on the smaller dataset, fine tunning takes advantage
# of the pre-trained model's already learned representation and refines them to fit the new task

# The fine-tuning process typically involoves three steps

# 1. Initialization: The pre- trained model is loaded and its parameters are frozen to preserve the learned representation
# Only the final layers or specific parts of the models are modified or replaced to match the requriments
# For examples, in an images classification model , and the last few layers responsible for predicting class label with new layers


# 2. Training: The frozen parameters are then fine tuned by training the modified model on the task specific dataset. This involves feeding the new dataset through the model , computing the loss and updating the model's parameters through backpropagation and gradient descent . The training process adjusts the models parameters to optimize its performance for the  specific task

# 3. Fine Tuning allows for faster and more effective training on new tasks especially when the available task specific data is limites, By levearging the knowledge encoded in the pre-trained model , fine tunning can achieve better performance and faster convergence compared to training a model from sctrach

# Images Data

# so far we have dealt with pretty straight forward data that has 1 or 2 dimensions. Now we are about to deal with images data that is usually made up of 3 dimensions .These 3 dimensions are as follow:
# 1.image height
# 2.image width
# 3.Color channels

# The only item in the list above you may not understand is color channels.
# The number of color channels represent the depth of an image and coorelates to the color used in it. For example , an images with three channels is likely made up of rgb(red,green,blue)pixels.So for rach pixel we have three numeric values in the range 0-255 that define its color.
#  For an image of color depth 1 we likely have a greyscale image with onw value defining each pixel again in the range of 0-255


# Dense layer
# A dense layer will consider the ENTIRE image. It will look at the pixels and use that informaion to genearte some output

# Convolutional layer
# The convolutional layer will look at speicfic parts of the images. In this example lets say it analyzes thehighlightes part below and detects pattern there

# How they Work
# A dense neural network learns patterns that are present in one specific area of an images.
# This means if a patterns that the network know is present in a different area of an image.
# It will have to learn the pattern again in that new area to be able to detect it

# n-f+1

# Feature Maps:
# This term simply stands for  3D tensor with two special axes(width and height) and one depth axis
# Our convolutional layers take feature maps as their input and return a newfeature map that  represent the presence of specific filters from the previous feature map.
# These are whar we call response map


# LAYER PARAMETER:
# A convolutional layer is defined by two key parameter

# Filter:
# A filter is a m x n pattern of pixels that we are looking for in an image.
# The number of filters in a convolutional layer represents how many patterns each layer is looking
# for and what the depth of our response map will be
# If we are looking for 32 different patterns/filters than our output feature map(aka the response map) will have a depth of 32.
#  Each one of the 32 layers of depth will be matrix of some size contaning values indicating if the filters was present
# at the location or not


#Sample size:
# This is not really the best term to describe this, but each convoltional layer is going to examine n*m blocks of pixels in each image
# We will consider 3*3 or 5*5 blocks. In the example above we use a 3*3 sample size. This size will be the same as the size of our filter
# Our layers work by sliding these filters of n*m pixels over evry possible position in our image
# and populating a new features map/response map indcating wheather the filter is present at each location

# Borders and Padding:
# The more mathematical of you have realized that if we slide a filter of lets say size 3*3
#  over our image well comsider less positions for our filter than pixels in our input
# This means our response map will have a slightly smaller width and height than our original image .
# This is fine but sometimes we want our response map to have the same dimensions.
# We can accomplish this by using something called padding

# Padding is simply addition of the appropriate number of rows and or columns
#  to your input data such that each pixels can be centered by the filter


# STRIDES:
# In the previous sections we assumed that the filter would be slide continously through the image such that it covered every possible position
# This is common but sometimes we introduce that idea of a stride to our convoltuional layer .
# The stride size represent how many rows and columns we will move the filter each time .
# These are not used very frequently so we will move on


# POOLING:
# The idea behind a pooling layers is to downsample our features maps and reduce their dimensions . They work in a similar way to convolutional
# layers where they extract windows from the features map and return a response map of the max , min or average values of each channel
# Pooling is usually done using windows of size 2*2 and a stride of 2. This will reduce the size of the feature
# map by a factor of two and return a response map that is 2x smaller

import tensorflow_datasets as tfds
tfds.disable_progress_bar()

# Split th data manually into 80% training and 10% testing and 10% validation
(raw_train , raw_validation, raw_test), metadata = tfds.load('cats_vs_dogs', split=['train[:80%]',
                                                                                   'train[80%:90%]',
                                                                                    'train[90%:]'],
                                                             with_info=True,
                                                             as_supervised=True)

get_label_name= metadata.features['label'].int2str

# The code you provided is accessing the int2str attribute of the label features in the metadata object .Lets break it down step by step

# Metadata: It refers to an object or structure that contains information about a datasets or the feature of a machine learning model
# The 'label' feature typicall represent the target variable or the class labels in a classification task

# int2str: It is a function or attribute associcated with the label figure
# In this case it indicates that the labels are encoded as integers and can be cob=nverted to their corresponding string representation

# Get_label_name: It is the variable that stores the reference to the int2str attribute , so it can be called later in the code to convert integer labels to their string representation

# Create a function object that we can use to get labels
# Display 2 images from the dataset

import matplotlib.pyplot as plt
for image , label in raw_train.take(2):
  plt.figure()
  plt.imshow(image)
  plt.title(get_label_name(label))

IMG_SIZE= 160 # All images will be resized to 160*160

IMG_SIZE=160 # All images will be resized to 160*160

def format_example(image, label):

  # return an image that is reshaped to IMG_SIZE

  image = tf.cast(image , tf.float32)
  image=(image/127.5)-1
  image=tf.image.resize(image, (IMG_SIZE , IMG_SIZE))
  return image , label

  # Now we can apply this function to all our image uisng map
train = raw_train.map(format_example)
validation = raw_validation.map(format_example)
test= raw_test.map(format_example)

# Now if we look at the shape of an original image vs the new image we will see it has been changed


for img , label in raw_train.take(2):
  print("Original Shape:" , img.shape)


for img , label in train.take(2):
  print("New shape:" , img.shape)

# Picking a pre trained Model ==
# This model we are going to use as the convolutional base
#  for our model is the MobileNet V2 Developed at google
# This model is trained on 1.4 million images and has 1000 different classes
# We want to use this model but onlt its convolutional base
# So when we load in the model we will specify that we dont want to load the top(classififcation)
# Layer. We willl tell the model what input shape to expect and to use the predetermined weights form imgenet (google dataset)

IMG_size=160 #Define the desried size for the input image

# Create the base model from th epre-trained model MobileNetV2
base_model = tf.keras.applications.MobileNetV2(
    input_shape =(IMG_SIZE, IMG_SIZE , 3),
    include_top=False,
    weights='imagenet'
)

base_model.summary()

# Frezzing the Base==>
# The term freezing refers to disabling the training property of a layer
# It simply means we wont make any changes to the weights of any layers
# That are frozen during training

base_model.trainable= False

# The code base_model.trainable = False is used to set the trainable attribute of the base_model to false

# In Tensorflo AND KKeras the trainable attribute is a boolean flag that determine
# whether the weights of a model or a specific layer
# within the model should be updated during training or not
# When the trainable is set to True , The weights of a model or layer can be updated based on the gradient computed during backpropagation
# However when trainable is set to False the weight remains frozen and their values are not updated during training

# By setting base_model.trainable = False , you are essentially frezzing the weights of the base_model (in this case
# The mobileNetv2 model and preventing them from being updated when you train your overall model)

# Adding the classifier

# Now that we have our base layer setup we can add the classifier
# Instead of flattening the features map of the base layer we will use a global avaerage pooling
# layer that will average the entire 5*5 area of each 2d features map and return to us a single 1289 element vector per filter

global_average_layer = tf.keras.layers.GlobalAveragePooling2D()

# Finally we will add the prediction layer that will be a single dense neuron
# We can do this because we only have two classes to predicted for

prediction_layer = tf.keras.layers.Dense(1)

# Now we will combine these layers together in a model

model = tf.keras.Sequential([
    base_model ,
    global_average_layer ,
    prediction_layer
])

model.summary()

base_learning_rate = 0.0001
model.compile(optimizer = tf.keras.optimizers.RMSprop(lr = base_learning_rate) ,
              loss = tf.keras.losses.BinaryCrossentropy(from_logits = True) ,
              metrics = ['accuracy'])
BATCH_SIZE = 32
SHUFFLE_BUFFER_SIZE = 1000

train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)
validation_batches = validation.batch(BATCH_SIZE)
test_batches = test.batch(BATCH_SIZE)

initial_epochs = 3
validation_steps = 20
loss0 , accuracy0 = model.evaluate(validation_batches , steps = validation_steps)

# Now we can train it our image
history = model.fit(train_batches,
                    epochs= initial_epochs,
                    validation_data=validation_batches)

acc=history.history['accuracy']
print(acc)

